- [[#概述和传输层服务|概述和传输层服务]]
- [[#多路复用/解复用|多路复用/解复用]]
	- [[#多路复用/解复用#TCP多路复用/解复用|TCP多路复用/解复用]]
	- [[#多路复用/解复用#UDP多路复用/解复用|UDP多路复用/解复用]]
- [[#无连接的服务（UDP）|无连接的服务（UDP）]]
	- [[#无连接的服务（UDP）#UDP报文格式|UDP报文格式]]
	- [[#无连接的服务（UDP）#检验和|检验和]]
- [[#可靠数据传输原理|可靠数据传输原理]]
	- [[#可靠数据传输原理#构造可靠数据传输协议|构造可靠数据传输协议]]
	- [[#可靠数据传输原理#流水线可靠数据传输协议|流水线可靠数据传输协议]]
- [[#面向连接的传输：TCP|面向连接的传输：TCP]]
	- [[#面向连接的传输：TCP#概述|概述]]
	- [[#面向连接的传输：TCP#TCP报文段结构|TCP报文段结构]]
	- [[#面向连接的传输：TCP#往返时间估计与超时|往返时间估计与超时]]
	- [[#面向连接的传输：TCP#可靠数据传输|可靠数据传输]]
	- [[#面向连接的传输：TCP#TCP流量控制|TCP流量控制]]
	- [[#面向连接的传输：TCP#TCP连接管理|TCP连接管理]]
- [[#拥塞控制|拥塞控制]]
	- [[#拥塞控制#拥塞原因/代价|拥塞原因/代价]]
	- [[#拥塞控制#拥塞控制方法|拥塞控制方法]]
- [[#TCP拥塞控制|TCP拥塞控制]]
	- [[#TCP拥塞控制#拥塞感知|拥塞感知]]
	- [[#TCP拥塞控制#拥塞控制方法|拥塞控制方法]]
	- [[#TCP拥塞控制#公平性|公平性]]

# 概述和传输层服务
服务：为运行在不同主机上的应用进程提供逻辑通信
- 发送方将应用层报文分成报文段，然后交给网络层
- 接收方将报文段进行重组，然后交给应用层

![[Pasted image 20230914172500.png]]

逻辑通信：
两个家庭通信的例子非常好的讲解了逻辑通信的含义，即运输层实际上只做了端到端交付后的进程到进程工作，但对于进程而言，这个运输层似乎就做完了所有运输服务，因而这就是一种逻辑通信。
![[Pasted image 20230914172530.png]]


IP的服务模型是尽力而为交付服务，这意味着IP尽它“最大的努力”在通信的主机之间交付报文段，但它并不做任何确保。特别是，它不确保报文段的交付，不保证报文段的按序交付，不保证报文段中数据的完整性。由于这些原因，IP被称为不可靠服务(unreliable service)。

因而运输层只能在IP服务模型的基础上打补丁，可以拓展一些功能，但有些功能则无法实现。像负责端到端的IP协议自己都无法保证传输时间，那么负责进程到进程的运输层协议当然无法保证传输时间。
![[Pasted image 20230914173211.png]]

# 多路复用/解复用
![[Pasted image 20230914190137.png]]
- 多路复用：在源主机从不同套接字中收集数据块，并为每个数据块封装上首部信息(这将在以后用于分解)从而生成报文段，然后将报文段传递到网络层，所有这些工作称为多路复用
- 多路解复用（多路分解）：将运输层报文段中的数据交付到正确的套接字的工作称为多路分解

## TCP多路复用/解复用
发送消息时，应用层向传输层传递Socket和对应数据，传输层进行封装后，接着传到网络层，网络层会根据TCP头部信息封装IP头部，然后通过网卡传递。接收消息同理。
![[Pasted image 20230914184704.png]]
TCP套接字包含四元组标识，发送主机和接收主机都依靠这四元组进行定位。

## UDP多路复用/解复用
发送消息时，应用层向传输层传递Socket、数据、目标IP和端口号（这是UDP的区别）。
![[Pasted image 20230914185502.png]]
在接收端，UDP套接字用二元组标识 (数据报中的目标IP地址、目标端口号)

如果两个不同源IP地址/源端口号的数据报，但是有相同的目标IP地址和端口号，则被定位到相同的套接字

# 无连接的服务（UDP）
![[Pasted image 20230914192025.png]]
发送方：
1. 从应用进程得到数据
2. 附加上为多路复用/多路分解所需的源和目的端口号及差错检测信息，形成报文段（数据报）
3. 递交给网络层，尽力而为的交付给接收主机

接收方：
1. 从网络层接收数据报
2. 根据目的端口号，将数据交付给相应的应用进程

## UDP报文格式
![[Pasted image 20230914193726.png]]
可知端口号都是16位的，因而就是从0~65535

## 检验和
从上述UDP报文格式可知，UDP需要计算校验和并进行传递。计算方式为，将所有字段按16比特进行相加，所得到的和进行反码运算，就是检验和。接收方按同样方式计算校验和，跟报文段中的检验和进行对比即可。

接收方也可以将数据和检验和全部相加，如果报文段没有改变则这个答案应该是一个全1的值（这个自己想想）。
![[Pasted image 20230914193854.png]]

检验码出错，则报文段肯定出错。检验码没出错，报文段也可能出错。此时就得重传。

事实上UDP也可以进行可靠传输，不过得在应用层中实现。

![[Pasted image 20231003094217.png]]

# 可靠数据传输原理
难点是如何在不可靠的信道传输基础上建立一个可靠的数据传输。
![[Pasted image 20230916201100.png]]

接下来我们只考虑单向的可靠数据传输问题（当然控制信息是双向传输的），实际上双向传输就是两个单项传输的综合，接下来我们将层层开发可靠的数据传输协议的发送方和接收方。
## 构造可靠数据传输协议
![[Pasted image 20230916202515.png]]
在Rdt1.0的情况下，我们的协议没有任何多余的功能，发送方只负责接受调用，然后封装分组并发送，一直都是一个状态。接收方也只负责接收分组，解封装后向上传递。


![[Pasted image 20230916202643.png]]
在这种情况下，发送方会计算校验和，接收方会根据校验和来检测数据是否出错，然后发送反馈。具体流程可见下：
![[Pasted image 20230917084323.png]]

rdt2.0有一个致命的错误就是没有考虑ACK、NAK控制报文的出错，因而我们引入序号机制，给每个分组都标上序号。如果ACK、NAK出错，发送方就只管重传，如果重复，接收方是可以根据需要进行判断然后丢弃的。很显然，这是一个**停等协议**
![[Pasted image 20230917090127.png]]
![[Pasted image 20230917090412.png]]
这里接收方发现重复后，是一样要发ACK的，表示已经收到过这个重复报文了，让发送方进入下一个状态。

rdt2.2：功能同rdt2.1，但只使用ACK(ack 要编号），使用对前一个数据单位的ACK，代替本数据单位的NAK。这是为之后流水线协议做准备

![[Pasted image 20230917093420.png]]
发送方进行超时检测，接收方不需要（因为只需要有一个超时就行了）
![[Pasted image 20230917094701.png]]
注意，这里收到错误的ACK后，不会做任何操作，而是等待超时，然后自动重发。

rdt3.0已经是一个完备的协议了，即能够实现正常功能，但由于是停等协议，效率过低。

## 流水线可靠数据传输协议
流水线：允许发送方在未得到确认的情况下，发送多个分组
- 增加序号范围：需要多个bit位来表示序号
- 发送方/接收方都需要有缓冲区：发送方可能需要重传、接收方可能乱序
- 两种常用的流水线协议是回退N步（GBN）、选择重传（SR）

**发送缓冲区**
定义：内存中的一个区域，落入缓冲区的分组可以发送
大小：一次最多可以发送多少个未经确认的分组
![[Pasted image 20230918091059.png]]

![[Pasted image 20230918090647.png]]

**发送窗口**
定义：在发送缓冲区中，已经发送但未经确认分组的序号构成的空间
后沿与前沿：后沿就是左边，前沿就是右边。一开始后沿=前沿
前沿移动：在不超过发送缓冲区的前提下，发送一个分组，前沿就前移
后沿移动：收到最老分组的确认，后沿前移，同时发送缓冲区跟着前移

**GBN**：拥有当前最老未确认分组的计时器，如果超时，就会回退到这个分组，重新发送整个发送窗口中的分组
**SR**：拥有所有未确认分组的计时器，哪个超时就重新发哪个

**接收窗口=接收缓冲区**
定义：收到的分组序号落在接收窗口内才能接收，否则丢弃
大小：大小=1，则只能顺序接收；大小>1，则可以乱序接收

**GBN**：GBN是大小=1的接收窗口，因而只能接收当前希望接收的序号分组。如果收到了不是当前序号的分组，接收端就会丢弃，同时发送当前已经收到的最高序号分组的确认（这样发送端就知道没有收到当前分组）
**SR**：SR是大小>1的接收窗口，因而会对每个落入接收窗口的序号分组发确认，同时如果当前最老的序号分组已经接收，就会将接收窗口前移，从而容纳下一个分组。

![[Pasted image 20230918150745.png]]

![[Pasted image 20230918150801.png]]

# 面向连接的传输：TCP
## 概述
![[Pasted image 20230919185637.png]]
其中MSS是不包括TCP头部的，单纯是（数据）报文段的大小

设置该MSS要保证一个TCP报文段（当封装在一个IP数据报中）加上TCP/IP首部长度（通常40字节）将适合单个链路层帧（MTU）。以太网和PPP链路层协议都具有1500字节的MTU,因此MSS的典型值为1460字节。

## TCP报文段结构
![[Pasted image 20230919191001.png]]
其中首部长度代表除应用层数据以外的长度。

**序号**
报文段首字节在字节流中的编号。发送方和接收方都有不同的起始序号，这个在建立连接的时候会进行交换。

**确认号**
期望从另一方收到的下一个字节的序号。TCP采用累计确认，但不是接收窗口大小为1，这个后面会提到。

**首部长度**
4比特的首部长度字段(header length field),该字段指示了以32比特的字为单位的TCP首部长度。因而该字段最大值就是15，表示15个字也就是60个字节。因而首部长度最大为60字节。

**接收窗口**
16比特的接收窗口字段(receive window field),该字段用于流量控制。

**标志字段**
6比特的标志字段(flag field) 。ACK比特用于指示确认字段中的值是有效的，即该报文段包括一个对已被成功接收报文段的确认。RST、SYN和FIN比特用于连接建立和拆除。

## 往返时间估计与超时
TCP如同前面3.4节所讲的rdt协议一样，它采用超时/重传机制来处理报文段的丢失问题。

**估计往返时间**
大多数TCP的实现仅在某个时刻做一次SampleRTT测量，而不是为每个发送的报文段测量一个SampleRTT。这就是说，在任意时刻，仅为一个已发送的但目前尚未被确认的报文段估计SampleRTT，从而产生一个接近每个RTT的新SampleRTT值。（不计算重传的RTT）

为使估计的RTT平滑，我们采用对测量值进行求平均，公式如下。这个加权平均对最近的样本赋予的权值要大于对旧样本赋予的权值，因而能更好反映网络当前拥塞状态。
![[Pasted image 20230919202824.png]]

>Q：为什么这个公式对最近样本的权值更大？
>A：从下图可以得知，当前样本权值为$α$，前一个就是$(1-α)*α$  ，以此类推。
>![[Pasted image 20230919204037.png]]


除了估算RTT外，测量RTT的变化也是有价值的。DevRTT用于估算SampleRTT一般会偏离EstimatedRTT的程度。很显然这也是个加权平均值。
![[Pasted image 20230919203029.png]]

**设置和管理超时重传间隔**
现在已经给出了EstimatedRTT值和DevRTT值，我们将用这两个值设置超时重传间隔。显然这个间隔应该大于EstimatedRTT，并需要加上一些余量，这就会用上DevRTT。因而最终计算公式如下：

![[Pasted image 20230919203233.png]]

推荐的初始Timeoutinterval值为1秒。同时，当出现超时后，Timeoutlnterval值将加倍，以免即将被确认的后继报文段过早出现超时。然而，只要收到报文段并更新EstimatedRTT，就使用上述公式再次计算Timeoutinterval。

## 可靠数据传输
![[Pasted image 20230919205857.png]]
这里就涉及了几个TCP的特点：
1. TCP采用累计确认，收到一个ACK后，发送方就认定该ACK之前的所有序号都已收到
2. 超时间隔翻倍
3. 快速重传：收到ACK50后，又接着收到三次，就说明不能等超时了，要直接开始重传
4. 只重传最早的未确认的报文段

这里说明了为什么会突然收到多个重复的ACK，因为如果接受了乱序，接收方只会发最早的未收到的报文段的ACK，这样就能帮助发送方进行快速重传。
![[Pasted image 20230919212914.png]]

![[Pasted image 20230919210954.png]]
这里显示了TCP发送方的三个事件：
1. 接收数据：从上层接收数据后，用NextSeqNum创建一个报文段交给IP层，更新NextSeqNum。如果当前没有定时器，则启动定时器（定时器与最早未确认的报文段关联）
2. 超时：超时间隔用前文提到的方法进行设置。超时后只重传最老的未确认报文段，然后重启定时器。
3. 收到确认：如果是对尚未确认的报文段确认，则更新SendBase（后沿），如果当前还有未确认的报文段，则重启定时器，否则关闭定时器。

这一部分稍微想想就能知道为什么：
![[Pasted image 20230919213318.png]]

## TCP流量控制
TCP为它的应用程序提供了流量控制服务(flow control service)以消除发送方使接收方缓存溢岀的可能性。流量控制因此是一个速度匹配服务，即发送方的发送速率与接收方应用程序的读取速率相匹配。

为实现这个目标，接收方和发送方都会维护一个接收窗口的变量，用于记录对方还有多少缓冲区。更新这个变量的方法是每次在返回的报文段中附带上rwnd字段，就可以更新了。
![[Pasted image 20230920084914.png]]

![[Pasted image 20230920085229.png]]

![[Pasted image 20230920085259.png]]

## TCP连接管理
TCP会用三次握手建立连接：
![[Pasted image 20230920090912.png]]

![[Pasted image 20230920092451.png]]

为什么不是两次握手：
![[Pasted image 20230920091605.png]]


连接关闭：
	客户应用进程发出一个关闭连接命令。这会引起客户TCP向服务器进程发送一个特殊的TCP报文段。这个特殊的报文段让其首部中的一个标志位即FIN比特被设置为1。当服务器接收到该报文段后，就向发送方回送一个确认报文段。然后，服务器发送它自己的终止报文段，其FIN比特被置为1。最后2该客户对这个服务器的终止报文段进行确认。此时，在两台主机上用于该连接的所有资源都被释放了。

![[Pasted image 20230920092429.png]]

# 拥塞控制
流量控制是一对TCP发送/接收方之间控制发送速度的问题，拥塞控制则是关于整个网络的问题。

非正式的定义: “太多的数据需要网络传输，超过了网络的处理能力”

拥塞的表现：
- 分组丢失（路由器缓冲区溢出）
- 分组经历较大延时（路由器缓冲延时）

## 拥塞原因/代价
场景1下就是最经典的情况，流量强度接近1后，排队延时就是接近无穷，不过接收速度和发送速度是可以相等的（在R/2以前）
![[Pasted image 20230924150248.png]]

在场景2中会出现重传的情况，但不会出现因为延时而重传，因而发送的都是有用的，只是会占用发送速度。因而最后有效输出是能接近R/2的。
![[Pasted image 20230924150413.png]]

在无法得知丢失信息的情况下，肯定会出现重传没必要重传的分组的情况，因而有效输出无法接近R/2。
![[Pasted image 20230924150551.png]]

在这种情况下，一个分组在下游丢失，那么其在上游的传输能力就被浪费了
![[Pasted image 20230924150905.png]]

## 拥塞控制方法
网络辅助的拥塞控制不是重点，咱就不做学习了。下一节我们开讲TCP采用的拥塞控制方法。
![[Pasted image 20230924152016.png]]

# TCP拥塞控制
TCP采用端到端的拥塞控制：
- 路由器不向主机有关拥塞的反馈信息
	- 路由器的负担较轻
	- 符合网络核心简单的TCP/IP架构原则
- 端系统根据自身得到的信息， 判断是否发生拥塞，从而采取动作

这里就涉及到两个问题：
1. 如何检测拥塞
2. 控制策略

## 拥塞感知
这张ppt写的很好了
![[Pasted image 20230924155510.png]]

## 拥塞控制方法
这个cwnd和流量控制中的rwnd一样，都是用来限制发送端发送窗口的大小，因而是取两个值中的最小值。rate的计算实际上就是单位时间内能发送的报文数。

注：这里的cong实际上是congestion，即拥堵
![[Pasted image 20230924160656.png]]

我们将这种控制方法称为AIMD（Additive- Increase, Multiplicative- Decrease）。也就是乘性减（直接减一半），线性增（线性的增加）。**其中指数增加到阈值时，只能算作阈值而不能超过。**
![[Pasted image 20230924164846.png]]

![[Pasted image 20230924171145.png]]

这里需要解释为什么会呈现锯齿形，乘性减后，阈值变为一半，CongWin直接变为1，但是因为是慢启动的指数型增加，所以这一小段时间可以忽略，然后到达阈值后又变成线性增加。这就是为什么拥塞窗口和时间呈现锯齿形。
![[Pasted image 20230924170324.png]]

## 公平性
我们忽略慢启动的状态（这个过程很快），那么两个连接都会到达阈值，然后开始线性增加。超过带宽后两个连接都会减半。之后不断重复该过程，最终会收敛到两个连接占用带宽相同的情况。（但实际上也只是理论公平，实际情况会比较复杂）
![[Pasted image 20230925091005.png]]

