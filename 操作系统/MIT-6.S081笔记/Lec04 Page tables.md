# 地址空间（Address Spaces）
给包括内核在内的所有应用程序提供专属的地址空间。对每个程序而言，它们的地址空间都是从0到某个地址结束。因而我们可以将地址空间看作一种抽象概念，可以把它想成是一个盒子，程序就只能在这个盒子里边使用，因而实现了隔离性。

在课本第二章的**2.5 进程概述**中也有提到，为了帮助加强隔离，进程抽象给程序提供了一种错觉，即它有自己的专用机器。进程为程序提供了一个看起来像是私有内存系统或地址空间的东西，其他进程不能读取或写入。进程还为程序提供了看起来像是自己的CPU来执行程序的指令。

![[Pasted image 20230912111722.png]]

顺着这个思路，我们就能得出要在一个物理内存上，创建不同的地址空间，因为归根到底，我们使用的还是一堆存放了内存信息的DRAM芯片。对此，我们使用了页表。

# 页表（Page Table）
## 抽象概念
既然要创建地址空间，我们就肯定要使用虚拟地址，并将这个虚拟地址映射到物理地址。

对于任何一条带地址的指令，其中的地址应该认为是虚拟内存地址而不是物理地址。虚拟内存地址会被转到内存管理单元（MMU，Memory Management Unit）

内存管理单元会将虚拟地址翻译成物理地址。之后这个物理地址会被用来索引物理内存，并从物理内存加载，或者向物理内存存储数据。

为了能够完成虚拟内存地址到物理内存地址的翻译，MMU会有一个表单，表单中，一边是虚拟内存地址，另一边是物理内存地址。（类似于一个键值对）

通常来说，内存地址对应关系的表单也保存在物理内存中。所以CPU中需要有一些寄存器用来存放表单在物理内存中的地址。这个寄存器就是SATP（RISC-V）。这样，CPU就可以告诉MMU，可以从哪找到将虚拟内存地址翻译成物理内存地址的表单。

![[Pasted image 20230912112741.png]]

>page table保存在物理内存中，MMU只是会去查看page table，然后完成翻译。

每个应用程序都有自己独立的表单，并且这个表单定义了应用程序的地址空间。所以当操作系统将CPU从一个应用程序切换到另一个应用程序时，同时也需要切换SATP寄存器中的内容，从而指向新的进程保存在物理内存中的地址对应表单。

以上就是我们对页表的一个抽象理解，这并不是实际的实现，但我们可以通过这种抽象的方式理解页表在建立地址空间中的作用。

## 实际情况
**一级映射**
基于上述的概念，我们可以得到下面一张图，这张图会贴近实际，但还不是最终实现：
![[Pasted image 20230912113725.png]]
1. 首先XV6基于Sv39 RISC-V运行，这意味着它只使用64位虚拟地址的低39位；而高25位不使用。
2. 在RISC-V中，物理内存地址是56bit。大多数主板还不支持2^56这么大的物理内存。
3. RISC-V页表在**逻辑**上是一个由 $2^{27}$ 个页表条目（Page Table Entries/PTE）组成的数组。这 $2^{27}$ 个页表条目由虚拟地址中的Index进行指引。
4. 每个PTE包含一个44位的物理页码（Physical Page Number/PPN）和10位的标志。
5. 我们用44位的物理页码PPN找到物理页，这个物理页是 $2^{12}$ 大小，也就是4096字节。
6. 我们使用虚拟地址末尾的12位作为物理页中的偏移，从而在4096字节中找到需要的地址。这就是我们翻译后的物理地址。

**Q/A**
>Q：图中的物理地址56bit又是根据什么确定的？
>A：这是由硬件设计人员决定的。所以RISC-V的设计人员认为56bit的物理内存地址是个不错的选择。可以假定，他们是通过技术发展的趋势得到这里的数字。比如说，设计是为了满足5年的需求，可以预测物理内存在5年内不可能超过2^56这么大。或许，他们预测是的一个小得多的数字，但是为了防止预测错误，他们选择了像2^56这么大的数字。
>Q：PTE中为什么还有10位空缺
>A：同样是保留用途，以后可以扩展物理地址

**三级映射**
通过前面的讲解，我们了解了页表在**逻辑**上的实现，但是目前的设计还不能满足实际的需求。在上图中，Page table有 $2^{27}$ 个条目，而每个进程都会有自己的Page table，这就是一个相当大的数字，会消耗大量的内存，而这其中又有很多条目实际是没有使用的，因而我们需要做出改进。

实际中，page table是一个多级的结构。下图是一个真正的RISC-V page table结构和硬件实现。
![[Pasted image 20230912115449.png]]
1. 之前提到的27位Index，实际上分为三段L2、L1、L0，分别为9位。
2. SATP存储最高一级Page Directory（与Page Table相同），L2为最高一级Page Directory的偏移。
3. 上一级Page Directory的PTE中存储的PPN，是下一级Page Directory的物理地址。然后又可以根据虚拟地址中的L字段进行寻找。
4. 最终我们就可以找到实际的物理地址，完成翻译。

从某种程度上，三级映射的方式与一级映射没有区别，但优点就在于每个Page Directory的大小比较小。举个例子，如果地址空间只使用了一个物理地址，那么我们就需要三个Page Directory，也就是 $3*512$个PTE，总计为 $3*4096$字节，与之前一次就需要 $2^{27}$个PTE相比，所需空间大大减少。

**PTE标志位**
上图已经给出了10个标志位的作用，其中比较有用的有：
- `PTE_V`指示PTE是否存在：如果它没有被设置，对页面的引用会导致异常（即不允许）。
- `PTE_R`控制是否允许指令读取到页面。
- `PTE_W`控制是否允许指令写入到页面。
- `PTE_X`控制CPU是否可以将页面内容解释为指令并执行它们。
- `PTE_U`控制用户模式下的指令是否被允许访问页面；如果没有设置`PTE_U`，PTE只能在管理模式下使用。

>Q：为什么44位的PPN能代表下一级Page Directory的物理地址
>A：在三级Page Directory中，一个Page Directory有 $2^9$ 即512个PTE，每个PTE都是64位，即8字节，的条目，因而整个Page Directory的大小就是4096字节，与之前概念中44位PPN寻找物理地址的方式相同。
>Q：为什么是PPN存在这些page directory中
>A：因为我们需要在物理内存中查找下一个page directory的地址（Page Directory存在物理内存中）

# 页表缓存
在上面的三级映射中，可能会发现这样会很花时间，因而我们可以采用Cache的思想，将虚拟地址和物理地址进行映射，这样就可以快速找到物理地址。

TLB是一个硬件上的实现，在MMU中。而在XV6中，我们在软件的层面上硬件的相同功能。

# 内核地址空间
以下就是内核虚拟地址与物理地址的映射：
![[Pasted image 20230912195523.png]]
**我们先看这张图的右边，也就是物理地址：**
- 最下边是未被使用的地址，是保留地址
- 0x1000是boot ROM，当你对主板上电，主板做的第一件事情就是运行存储在boot ROM中的代码。当boot完成之后，会跳转到地址0x80000000，操作系统的就从这里启动。
- 然后是一些I/O设备：
	- PLIC是中断控制器（Platform-Level Interrupt Controller）
	- CLINT（Core Local Interruptor）也是中断的一部分。所以多个设备都能产生中断，需要中断控制器来将这些中断路由到合适的处理函数
	- UART0（Universal Asynchronous Receiver/Transmitter）负责与Console和显示器交互
	- VIRTIO disk，与磁盘进行交互
- 0x80000000开始就是物理内存RAM
- 接着还有一段未被使用的内存空间

**接下来看这张图的左边，这就是XV6的虚拟内存空间**。当机器刚刚启动时，还没有可用的page，XV6操作系统会设置好内核使用的虚拟地址空间，也就是这张图左边的地址分布。

为了让XV6清晰易懂，大部分虚拟地址都直接映射到物理地址，即两者是相等的。

虚拟地址设置了权限，这从图中可以看出。

>Q：对于不同的进程会有不同的kernel stack吗？
>A：答案是的。每一个用户进程都有一个对应的kernel stack

# 进程地址空间（也就是用户地址空间）
每个进程都有一个单独的页表，当xv6在进程之间切换时，也会更改页表。以下就是进程地址空间：
![[Pasted image 20230912202751.png]]
进程地址空间使用页表有以下好处：
1. 不同进程的页表将用户地址转换为物理内存的不同页面，这样每个进程都拥有私有内存
2. 每个进程看到的自己的内存空间都是以0地址起始的连续虚拟地址，而进程的物理内存可以是非连续的
3. 内核在用户地址空间的顶部映射一个带有蹦床（trampoline）代码的页面，这样在所有地址空间都可以看到一个单独的物理内存页面（这一条不是很懂）

Xv6为每个进程维护一个单独的页表，定义了该进程的地址空间。如图所示的进程地址空间中，首先是指令，然后是全局变量，然后是栈区，最后是一个堆区域（用于`malloc`）以供进程根据需要进行扩展。










